#机器学习算法

##推荐系统常用算法

- 关联规则
- Slope one
- SVD


##预测算法
- ARIMA
- GM（N，M）
- SARIMA
- 多元回归
- ARMAX-GARCH

##数据降维
- PCA
- K-PCA

##主题模型
- LDA

##群体识别
- User-based collaborative filter 
- Item-based
- Slop-one
- 基于聚类的
- 基于SVD的
- 基于RBM的

##最优化方法
- SQP
- L-BFGS

##聚类算法（无监督学习）

###定义
找到这样的几组对象，类内相近，类外相远
###算法模型
1.从数据文本中提取特征
2.聚类算法
3.得到未知类簇

###相似度
1.欧式距离 
2.文科夫斯基距离
3.余弦相似度
4.Jaccard距离

###常见方法

####基于划分的
- KMeans
- Fuzzy KMeans
- KMediods
####基于层次的
- 层次聚类（自顶向下、自底向上）

####基于密度的
- DBSCAN
- OPTICS

####基于图的

####基于网格的
- CLIQUE

####在线聚类
- STC

####主题模型
- LDA


- Dirichet
- Canopy
- KMeansSpectral
- 混合高斯模型

###应用场景
- 寻找优质客户
- 推荐系统
- 偏好分析

##分类算法（有监督学习）
1.从数据文本中提取特征值
2.1.从样本数据（样本数据进行标注，分类N）中提取特征值
2.2.用样本数据训练分类算法
3.通过分类算法得到数据的分类情况

- 逻辑回归
- 随机森林
- 隐马模型
- KNN
- 神经网络
- SVM

##矩阵分解
- SVD
- QR

##深度学习
- 基于Kmeans的
- 稀疏编码
- DBN
- 基于RBM的


##关联规则算法

挖掘目标：频繁模式，频繁项集，关联规则

eg：


关联规则：就是有关联的规则，买啤酒就会购买尿布，{啤酒}-->{尿布}就是一条关联规则
支持度：support(X-->Y)，此规则出现的概率，如啤酒和尿布同时出现的次数/数据记录数 = 3/5=60%
置信度： confidence(X-->Y)，规则出现次数/Y出现次数
啤酒和尿布同时出现的次数/啤酒出现的次数=3/3=100%
啤酒和尿布同时出现的次数/尿布出现的次数=3/4=75%

最小支持度阈值和最小置信度阈值:由挖掘者戒领域专家设定
项集:项(商品)的集合
k-项集:k个项组成的项集
频繁项集:满足最小支持度的项集,频繁k-项集一般记为Lk
强关联规则:满足最小支持度阈值和最小置信度阈值的规则

- Apriori
Apriori定律
如果一个集合是频繁项集，则它的所有子集都是频繁项集
如果一个集合不是频繁项集，则它的所有超集都不是频繁项集


Apriori算法可以分成 连接,剪枝 两个步骤不断循环重复

- FP-growth

//TODO

-----
#搜索算法

##网络爬虫

思想：把网络看成一个图，站点是节点，链接是弧。利用图论，做深度遍历，或者广度遍历。

把爬取的网址做成索引，把爬取的页面存储起来。

工程实现要点：
1.考虑先大级别广度遍历，再单网站深度遍历。
2.考虑提前动态页面的url，需要模拟浏览器渲染页面
3.记录已下载的url表由于太大需要多机存储，即哈系表成为通信瓶颈。
  优化：调度器，1根据url选定由哪台机器做，2批量查询url发送给该机器，或批量更新发给该机器

##索引方法（等价于布尔运算）
将查询语句转换为布尔运算的算式。
将某关键字出现在每篇文献，作为一个向量，出现置1,不出现置0。
对分词组合做And操作，获得同时出现的文献编号。

思想：将数据量子化。用布尔0,1完全分类

大量索引时，根据网页序号shards分布式的存在多台服务器上，

对索引按常用不常用，或级别分类。

##分词算法

- 基于字典 ansj
- 基于统计的 ，理念是找出句子中分词组合概率最大的，作为分词方法
  将P（a1,a2,a3,...,an）先转换为条件概率相乘，再通过马尔可夫近似为，n元模型，然后利用动态规划用Viterbi
 算法快速找到分词

关键困难：歧义消除、新语义词

##关键字提取

###词频相关方法
- TFIDF逆文档词频

###图相关方法
- PageRank
- TextRank
- HITS

##信息指纹

what：任何一个信息，都可以对应一个不太长的随机数，称其为指纹。
思想：将一段信息随机的映射到多维二进制空间的一个点。只要随机函数好，该点可做指纹。

char：
1.转换不可逆

when：加密、信息压缩、信息处理

信息处理：
eg1.如何判定集合相同：将集合中的元素一一做信息指纹fpi，然后求和。比较两集合的求和值是否相等。时间复杂度O（n），不需要额外空间
eg2.相似哈希：将文章分片，用TFIDF找出特征值，

how：
1.将字符串看成一个特殊、很长的整数
2.伪随机数产生算法（Pseudo-Random Number Generator）

###常见伪随机数产生算法

- 梅森旋转算法
- 基于加密的伪随机数产生算法
  1.MD5
  2.SHA-1

----
#社交网络分析
（social network analysis）SNA

//TODO



#算法详细

##page-rank
思想：一个网页被更多的其他网页所链接，则说明他受到普遍承认，它的排名就高

how: 

##K-means

###算法思想
– 1:随机选择K个点作为初始质心
– 2:repeat
– 3: 将每个点指派到最近的质心,形成K个簇
– 4: 重新计算每个簇的质心
– 5:until 质心不发生变化

###算法特征
– 有利于发现球形或圆形簇
– 复杂度低,为O(NKt),其中N是对象点的个数,t 是迭代次数
– K值不易确定,且可能产生空簇
– 对初始质心有一定的依赖性

##Canopy聚类

###算法思想
– 1: 设置阈值 T1, T2, 且T1>T2
– 2: 将相似的对象放在一个子集中,生成多个canopy集
– 3: 对各个canopy内使用K-means聚类

###算法特征
– 不需要设置 k 值,但是需要设置 T1,T2 两个阈值
– 可并行化,计算速度快
– 通常先用 canopy聚类来确定k值,再进行k-means聚类

##模糊k均值(Fuzzy K-means)

###数学背景

– 模糊集合论、模糊逻辑
– 隶属度:对象属于某个集合的概率
数据点集 X = {X1,X2,...,Xn}, 模糊簇集 C = {C1,C2,...,Ck};
– 给定点Xi的所有权值之和为1:
– 每个簇Cj 以非零权值至少包含一个点,但不以权值1包含所有点:

### 算法思想
– 1: 选择一个初始模糊划分,即对所有点赋初始权值
– 2: repeat
– 3: 使用模糊划分,计算每个簇的质心
– 4: 重新计算模糊划分,即Wij
– 5: until 质心不发生变化




##多元线性回归

步骤1：

首先，将每个权重都设为1.0：

步骤2：

将每栋房产带入你的函数运算，检验估算值与正确价格的偏离程度：

运用你的程序预测房屋价格。

例如：上表中第一套房产实际成交价为25万美元，你的函数估价为17.8万，这一套房产你就差了7.2万。

再将你的数据集中的每套房产估价偏离值平方后求和。假设数据集中有500套房产交易，估价偏离值平方求和总计为86,123,373美元。这就反映了你的函数现在的“正确”程度。

现在，将总计值除以500，得到每套房产的估价偏离平均值。将这个平均误差值称为你函数的代价。

如果你能调整权重使得这个代价变为0，你的函数就完美了。它意味着，根据输入的数据，你的程序对每一笔房产交易的估价都是分毫不差。而这就是我们的目标——尝试不同的权重值以使代价尽可能的低。

步骤3：

不断重复步骤2，尝试所有可能的权重值组合。哪一个组合使得代价最接近于0，它就是你要使用的，你只要找到了这样的组合，问题就得到了解决!

当然你不可能尝试所有可能的权重值来找到效果最好的组合。那可真要花很长时间，因为要尝试的数字可能无穷无尽。
为避免这种情况，数学家们找到了很多聪明的办法来快速找到优秀的权重值，而不需要尝试过多

这种找出最佳权重的办法被称为批量梯度下降